# -*- coding: utf-8 -*-
"""KidneyDiseases.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17fWMRnm6oPX9-tMgT1h-uPklznwL2x6c
"""

from google.colab import drive
drive.mount('/content/drive')

import os

# Path to the extracted dataset folder
dataset_path = '/content/drive/MyDrive/dataset/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'  # Update this path if needed

# Check if the folder exists
if os.path.exists(dataset_path):
    print("Dataset folder exists and is ready for use!")
else:
    print("Dataset folder does not exist. Please verify the path.")

import os

base_dir = '/content/drive/MyDrive/dataset/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'  # Update this path to where you want to extract the dataset
print("Contents of the dataset folder:", os.listdir(base_dir))

!pip install opencv-python-headless

import os
import numpy as np
import matplotlib.pyplot as plt
import cv2
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 1. Data Paths
base_dir = '/content/drive/MyDrive/dataset/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'
categories = ['Normal', 'Stone', 'Cyst', 'Tumor']

# 2. Preprocess Images with CLAHE
def preprocess_image_with_CLAHE(image_path):
    """
    Reads an image from the given path, converts it to grayscale,
    applies CLAHE, and resizes it to the target size.
    """
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced_image = clahe.apply(image)  # Apply CLAHE
    resized_image = cv2.resize(enhanced_image, (128, 128))  # Resize to (128, 128)
    return resized_image

# 3. Load and Prepare Dataset
def load_dataset(base_dir, categories):
    """
    Load images from each category folder, apply CLAHE, and store them in a NumPy array.
    """
    images = []
    labels = []
    for label, category in enumerate(categories):
        path = os.path.join(base_dir, category)
        for img_name in os.listdir(path):
            try:
                img_path = os.path.join(path, img_name)
                img = preprocess_image_with_CLAHE(img_path)
                images.append(img)
                labels.append(label)
            except Exception as e:
                print(f"Error loading image {img_path}: {e}")

    images = np.array(images).reshape(-1, 128, 128, 1)  # Add channel dimension
    labels = np.array(labels)
    return images, labels

# 4. Load Data
X, y = load_dataset(base_dir, categories)

# 5. Normalize Images
X = X / 255.0  # Normalize pixel values to [0, 1]

# 6. Split Data into Training and Testing Sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 7. Build Model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')  # 4 categories for classification
])

# 8. Compile Model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 9. Train Model
history = model.fit(X_train, y_train, epochs=5, validation_split=0.2, batch_size=32)

# 10. Evaluate Model
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc * 100:.2f}%")

# Plotting accuracy and loss
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# 11. Save the Model
model.save('/content/kidney_disease_classifier.h5')

# 12. Function to Predict on New Images
def predict_disease(image_path, model):
    """
    Preprocess an input image and use the trained model to predict the disease.
    """
    image = preprocess_image_with_CLAHE(image_path)
    image = image.reshape(1, 128, 128, 1) / 255.0  # Normalize and add batch dimension
    prediction = model.predict(image)
    predicted_label = categories[np.argmax(prediction)]
    return predicted_label

new_image_path = '/content/drive/MyDrive/dataset/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Cyst/Cyst- (10).jpg'
print(f"Predicted Disease: {predict_disease(new_image_path, model)}")

new_image_path = '/content/drive/MyDrive/DataSet/CT-KIDNEY-DATASET/dataset/Final Test/Tumour/Tumor- (139).jpg'
print(f"Predicted Disease: {predict_disease(new_image_path, model)}")

new_image_path = '/content/drive/MyDrive/dataset/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/Stone/Stone- (1).jpg'
print(f"Predicted Disease: {predict_disease(new_image_path, model)}")

new_image_path = '/content/drive/MyDrive/DataSet/CT-KIDNEY-DATASET/dataset/Final Test/Normal/Normal- (111).jpg'
print(f"Predicted Disease: {predict_disease(new_image_path, model)}")